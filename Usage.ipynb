{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f06249c6-eae5-43e6-a366-7893ad394cf0",
   "metadata": {},
   "source": [
    "# stable-dreamfusion setting\n",
    "\n",
    "## Instant-NGP NeRF Backbone\n",
    "\n",
    "```\n",
    "# + faster rendering speed\n",
    "# + less GPU memory (~16G)\n",
    "# - need to build CUDA extensions (a CUDA-free Taichi backend is available)\n",
    "```\n",
    "\n",
    "### train with text prompt (with the default settings)\n",
    "\n",
    "```\n",
    "# `-O` equals `--cuda_ray --fp16`\n",
    "# `--cuda_ray` enables instant-ngp-like occupancy grid based acceleration.\n",
    "python main.py --text \"a hamburger\" --workspace trial -O\n",
    "```\n",
    "\n",
    "```\n",
    "# reduce stable-diffusion memory usage with `--vram_O` \n",
    "# enable various vram savings (https://huggingface.co/docs/diffusers/optimization/fp16).\n",
    "python main.py --text \"a hamburger\" --workspace trial -O --vram_O\n",
    "```\n",
    "\n",
    "```\n",
    "# You can collect arguments in a file. You can override arguments by specifying them after `--file`. Note that quoted strings can't be loaded from .args files...\n",
    "python main.py --file scripts/res64.args --workspace trial_awesome_hamburger --text \"a photo of an awesome hamburger\"\n",
    "```\n",
    "\n",
    "```\n",
    "# use CUDA-free Taichi backend with `--backbone grid_taichi`\n",
    "python3 main.py --text \"a hamburger\" --workspace trial -O --backbone grid_taichi\n",
    "```\n",
    "\n",
    "```\n",
    "# choose stable-diffusion version (support 1.5, 2.0 and 2.1, default is 2.1 now)\n",
    "python main.py --text \"a hamburger\" --workspace trial -O --sd_version 1.5\n",
    "```\n",
    "\n",
    "```\n",
    "# use a custom stable-diffusion checkpoint from hugging face:\n",
    "python main.py --text \"a hamburger\" --workspace trial -O --hf_key andite/anything-v4.0\n",
    "```\n",
    "\n",
    "```\n",
    "# use DeepFloyd-IF for guidance (experimental):\n",
    "python main.py --text \"a hamburger\" --workspace trial -O --IF\n",
    "python main.py --text \"a hamburger\" --workspace trial -O --IF --vram_O # requires ~24G GPU memory\n",
    "```\n",
    "\n",
    "```\n",
    "# we also support negative text prompt now:\n",
    "python main.py --text \"a rose\" --negative \"red\" --workspace trial -O\n",
    "```\n",
    "\n",
    "### after the training is finished:\n",
    "\n",
    "```\n",
    "# test (exporting 360 degree video)\n",
    "python main.py --workspace trial -O --test\n",
    "# also save a mesh (with obj, mtl, and png texture)\n",
    "python main.py --workspace trial -O --test --save_mesh\n",
    "# test with a GUI (free view control!)\n",
    "python main.py --workspace trial -O --test --gui\n",
    "```\n",
    "\n",
    "## Vanilla NeRF backbone\n",
    "\n",
    "```\n",
    "# + pure pytorch, no need to build extensions!\n",
    "# - slow rendering speed\n",
    "# - more GPU memory\n",
    "```\n",
    "\n",
    "### train\n",
    "\n",
    "```\n",
    "# `-O2` equals `--backbone vanilla`\n",
    "python main.py --text \"a hotdog\" --workspace trial2 -O2\n",
    "```\n",
    "\n",
    "```\n",
    "# if CUDA OOM, try to reduce NeRF sampling steps (--num_steps and --upsample_steps)\n",
    "python main.py --text \"a hotdog\" --workspace trial2 -O2 --num_steps 64 --upsample_steps 0\n",
    "```\n",
    "\n",
    "### test\n",
    "\n",
    "```\n",
    "python main.py --workspace trial2 -O2 --test\n",
    "python main.py --workspace trial2 -O2 --test --save_mesh\n",
    "python main.py --workspace trial2 -O2 --test --gui # not recommended, FPS will be low.\n",
    "```\n",
    "\n",
    "## DMTet finetuning\n",
    "\n",
    "### use --dmtet and --init_with <nerf checkpoint> to finetune the mesh at higher reslution\n",
    "    \n",
    "```\n",
    "python main.py -O --text \"a hamburger\" --workspace trial_dmtet --dmtet --iters 5000 --init_with trial/checkpoints/df.pth\n",
    "```\n",
    "    \n",
    "### test & export the mesh\n",
    "    \n",
    "```\n",
    "python main.py -O --text \"a hamburger\" --workspace trial_dmtet --dmtet --iters 5000 --test --save_mesh\n",
    "```\n",
    "    \n",
    "### gui to visualize dmtet\n",
    "    \n",
    "```\n",
    "python main.py -O --text \"a hamburger\" --workspace trial_dmtet --dmtet --iters 5000 --test --gui\n",
    "```\n",
    "    \n",
    "## Image-conditioned 3D Generation\n",
    "\n",
    "### preprocess input image\n",
    "    \n",
    "```\n",
    "# note: the results of image-to-3D is dependent on zero-1-to-3's capability. For best performance, the input image should contain a single front-facing object. Check the examples under ./data.\n",
    "# this will exports `<image>_rgba.png`, `<image>_depth.png`, and `<image>_normal.png` to the directory containing the input image.\n",
    "python preprocess_image.py <image>.png \n",
    "python preprocess_image.py <image>.png --border_ratio 0.4 # increase border_ratio if the center object appears too large and results are unsatisfying.\n",
    "```\n",
    "    \n",
    "### train\n",
    "\n",
    "```\n",
    "# pass in the processed <image>_rgba.png by --image and do NOT pass in --text to enable zero-1-to-3 backend.\n",
    "python main.py -O --image <image>_rgba.png --workspace trial_image --iters 5000\n",
    "```\n",
    "\n",
    "```\n",
    "# if the image is not exactly front-view (elevation = 0), adjust default_theta (we use theta from 0 to 180 to represent elevation from 90 to -90)\n",
    "python main.py -O --image <image>_rgba.png --workspace trial_image --iters 5000 --default_theta 80\n",
    "```\n",
    "    \n",
    "```\n",
    "# by default we leverage monocular depth estimation to aid image-to-3d, but if you find the depth estimation inaccurate and harms results, turn it off by:\n",
    "python main.py -O --image <image>_rgba.png --workspace trial_image --iters 5000 --lambda_depth 0\n",
    "```\n",
    "    \n",
    "```\n",
    "python main.py -O --image <image>_rgba.png --workspace trial_image_dmtet --dmtet --init_with trial_image/checkpoints/df.pth\n",
    "```\n",
    "    \n",
    "```\n",
    "# providing both --text and --image enables stable-diffusion backend (similar to make-it-3d)\n",
    "python main.py -O --image hamburger_rgba.png --text \"a DSLR photo of a delicious hamburger\" --workspace trial_image_text --iters 5000\n",
    "```\n",
    "    \n",
    "```\n",
    "python main.py -O --image hamburger_rgba.png --text \"a DSLR photo of a delicious hamburger\" --workspace trial_image_text_dmtet --dmtet --init_with trial_image_text/checkpoints/df.pth\n",
    "```\n",
    "    \n",
    "### test / visualize\n",
    "    \n",
    "```\n",
    "python main.py -O --image <image>_rgba.png --workspace trial_image_dmtet --dmtet --test --save_mesh\n",
    "python main.py -O --image <image>_rgba.png --workspace trial_image_dmtet --dmtet --test --gui\n",
    "```\n",
    "    \n",
    "## Debugging\n",
    "\n",
    "```\n",
    "# Can save guidance images for debugging purposes. These get saved in trial_hamburger/guidance.\n",
    "# Warning: this slows down training considerably and consumes lots of disk space!\n",
    "python main.py --text \"a hamburger\" --workspace trial_hamburger -O --vram_O --save_guidance --save_guidance_interval 5 # save every 5 steps\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be87c5a-909d-434f-9f6d-03a06692e1d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p39",
   "language": "python",
   "name": "conda_pytorch_p39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
